package scheduler

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"gorm.io/gorm"
	"log"
	"math/big"
	"net/http"
	"pool/global"
	"pool/models"
	"strconv"
	"strings"
	"sync"
	"time"
)

const (
	poolApiURL = "https://explorer.coinex.com/res/btc/pools/distribution?page=1&limit=50&period=24h"
)

type HashRateResponse struct {
	Code int `json:"code"`
	Data struct {
		Code      int `json:"code"`
		Count     int `json:"count"`
		CurrPage  int `json:"curr_page"`
		Data      []*models.Pool
		HasNext   bool `json:"has_next"`
		Total     int  `json:"total"`
		TotalPage int  `json:"total_page"`
	} `json:"data"`
	Message string `json:"message"`
}

func fetchPoolInfo() ([]*models.Pool, error) {
	client := http.Client{Timeout: requestTimeout}

	var pools []*models.Pool

	for attempt := 1; attempt <= retryCount; attempt++ {
		resp, err := client.Get(poolApiURL)
		if err != nil {
			log.Printf("âš ï¸ [ç¬¬ %d æ¬¡å°è¯•] èŽ·å–çŸ¿æ± ä¿¡æ¯å¤±è´¥: %v", attempt, err)
			time.Sleep(retryDelay)
			continue
		}

		// è§£æž JSON
		var result HashRateResponse
		if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
			log.Printf("âš ï¸ [ç¬¬ %d æ¬¡å°è¯•] è§£æžçŸ¿æ± æ•°æ®å¤±è´¥: %v", attempt, err)
			time.Sleep(retryDelay)
			continue
		}

		pools = result.Data.Data

		err = resp.Body.Close()
		if err != nil {
			return nil, err
		}

		break
	}

	if len(pools) == 0 {
		return nil, fmt.Errorf("èŽ·å–åŒºå—æ•°æ®å¤±è´¥ï¼Œé‡è¯• %d æ¬¡ä»æ— ç»“æžœ", retryCount)
	}

	return pools, nil
}

func savePoolInfo(pools []*models.Pool) error {
	if len(pools) == 0 {
		return nil
	}

	// è¿‡æ»¤æŽ‰ pool_name ä¸º "NETWORK" çš„çŸ¿æ± 
	var filteredPools []*models.Pool
	for _, pool := range pools {
		if !strings.EqualFold(pool.PoolName, "NETWORK") { // å¿½ç•¥å¤§å°å†™æ¯”è¾ƒ
			filteredPools = append(filteredPools, pool)
		}
	}

	// å¦‚æžœè¿‡æ»¤åŽæ²¡æœ‰å‰©ä½™æ•°æ®ï¼Œç›´æŽ¥è¿”å›ž
	if len(filteredPools) == 0 {
		log.Println("âš ï¸  æ²¡æœ‰éœ€è¦æ’å…¥çš„çŸ¿æ± æ•°æ® (æ‰€æœ‰æ•°æ®è¢«è¿‡æ»¤)")
		return nil
	}

	var savedPools []*models.Pool
	// ä¿®æ”¹æ•°æ®ï¼Œä¿å­˜å‰ä¸ƒä¸ªï¼Œå‰©ä½™çš„åˆå¹¶åˆ°ä¸€èµ·
	var frontRadio float64
	if len(filteredPools) >= 7 {
		for i := 0; i < len(filteredPools); i++ {
			if i <= 6 {
				savedPools = append(savedPools, filteredPools[i])
				parseFloat, err := strconv.ParseFloat(filteredPools[i].Ratio, 64)
				if err != nil {
					continue
				}
				frontRadio += parseFloat
			}
		}
	}

	otherRadio := 1 - frontRadio

	bigHashFloat := new(big.Float)
	bigHashFloat.SetString(filteredPools[0].Hashps)
	bigRadioFloat := new(big.Float)
	bigRadioFloat.SetString(filteredPools[0].Ratio)
	allHashBigFloat := new(big.Float).Quo(bigHashFloat, bigRadioFloat)
	otherRadioStr := strconv.FormatFloat(otherRadio, 'f', 4, 64)
	bigOtherRadioFloat := new(big.Float)
	bigOtherRadioFloat.SetString(otherRadioStr)
	bigOtherHashFloat := new(big.Float).Mul(allHashBigFloat, bigOtherRadioFloat)

	// è®¡ç®—å…¨éƒ¨çš„ hash
	combinedPools := &models.Pool{
		Hashps:   bigOtherHashFloat.Text('f', -1),
		PoolName: "å…¶å®ƒ",
		Ratio:    strconv.FormatFloat(otherRadio, 'f', 4, 64),
	}

	savedPools = append(savedPools, combinedPools)

	for _, pool := range savedPools {
		// æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å·²å­˜åœ¨è¯¥çŸ¿æ± 
		var existingPool *models.Pool
		if err := global.GormDB.Model(&models.Pool{}).Where("pool_name = ?", pool.PoolName).First(&existingPool).Error; err != nil {
			if errors.Is(err, gorm.ErrRecordNotFound) {
				// ä¸å­˜åœ¨åˆ™æ’å…¥
				if err := global.GormDB.Create(pool).Error; err != nil {
					log.Println("âŒ æ’å…¥å¤±è´¥:", err)
				} else {
					//log.Println("âœ… æ’å…¥æˆåŠŸ:", pool.PoolName)
				}
			} else {
				log.Println("âŒ æŸ¥è¯¢å‡ºé”™:", err)
			}
		} else {
			// å­˜åœ¨åˆ™æ›´æ–°
			existingPool.Hashps = pool.Hashps
			existingPool.Ratio = pool.Ratio
			floatRadio, err := strconv.ParseFloat(existingPool.Ratio, 64)
			if err != nil {
				continue
			}

			//	pool.Price = pool.Ratio / (1 - pool.Profit)
			//existingPool.Price = floatRadio / (1 - existingPool.Profit)
			value := floatRadio / (1 - existingPool.Profit)
			formattedValue := strconv.FormatFloat(value, 'f', 4, 64)       // æ ¼å¼åŒ–ä¸º 4 ä½å°æ•°çš„å­—ç¬¦ä¸²
			existingPool.Price, _ = strconv.ParseFloat(formattedValue, 64) // è½¬å›ž float64

			if err := global.GormDB.Save(&existingPool).Error; err != nil {
				log.Println("âŒ æ›´æ–°å¤±è´¥:", err)
			} else {
				//log.Println("âœ… æ›´æ–°æˆåŠŸ:", existingPool.PoolName)
			}
		}
	}

	//// æ‰¹é‡æ’å…¥
	//result := global.GormDB.Model(&models.Pool{}).Clauses(clause.OnConflict{
	//	Columns:   []clause.Column{{Name: "pool_name"}},
	//	DoUpdates: clause.AssignmentColumns([]string{"hashps", "ratio"}),
	//}).Create(&savedPools)
	//if result.Error != nil {
	//	return fmt.Errorf("âŒ æ•°æ®åº“å†™å…¥å¤±è´¥: %v", result.Error)
	//}
	//
	//log.Printf("âœ… æˆåŠŸæ’å…¥ %d æ¡çŸ¿æ± æ•°æ®", result.RowsAffected)

	return nil
}

func StartPoolScheduler(ctx context.Context, wg *sync.WaitGroup) {
	defer wg.Done()

	poolInfo, err := fetchPoolInfo()
	if err != nil {
		log.Println("âŒ èŽ·å–çŸ¿æ± ä¿¡æ¯å¤±è´¥:", err)
	} else {
		err = savePoolInfo(poolInfo)
		if err != nil {
			log.Printf("âŒ ä¿å­˜çŸ¿æ± ä¿¡æ¯å¤±è´¥: %v", err)
		}
	}

	ticker := time.NewTicker(syncInterval)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			poolInfo, err := fetchPoolInfo()
			if err != nil {
				log.Println(err)
				continue
			}

			err = savePoolInfo(poolInfo)
			if err != nil {
				log.Printf("âŒ ä¿å­˜çŸ¿æ± ä¿¡æ¯å¤±è´¥: %v", err)
			}
		case <-ctx.Done():
			log.Println("ðŸ›‘ å®šæ—¶ä»»åŠ¡å·²åœæ­¢")
			return
		}
	}
}
